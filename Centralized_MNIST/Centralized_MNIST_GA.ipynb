{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/rohaan/Desktop/storage/RIT/federated_learning_lab/federated_learning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if len(os.getcwd().split('/')) != 8:\n",
        "    os.chdir('..')\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "KRVG5spLX-G6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)           # For CPU\n",
        "    torch.cuda.manual_seed(seed)      # For CUDA (if using GPU)\n",
        "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
        "    np.random.seed(seed)              # For NumPy\n",
        "    random.seed(seed)                 # For Python's built-in random\n",
        "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
        "    torch.backends.cudnn.benchmark = False     # Turn off optimization for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "\t-> TRAIN: available\n",
            "\t-> TEST: available\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to 32x32 as required by LeNet-5\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "print(f\"Datasets:\\n\\t-> TRAIN: {'available' if train_dataset else 'N/A'}\\n\\t-> TEST: {'available' if train_dataset else 'N/A'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "\t-> TRAIN: 60000 samples\n",
            "\t-> TEST: 10000 samples\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "print(f\"Datasets:\\n\\t-> TRAIN: {len(train_loader.dataset)} samples\\n\\t-> TEST: {len(test_loader.dataset)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # kernel_size aka filter size\n",
        "        # out_channels aka number of filters\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # layer 1\n",
        "        x = self.conv1(x)\n",
        "        x = torch.tanh(x) \n",
        "        # layer 2\n",
        "        x = nn.functional.avg_pool2d(input=x, kernel_size=2, stride=2)\n",
        "        x = torch.tanh(x) \n",
        "        # layer 3\n",
        "        x = self.conv2(x)\n",
        "        x = torch.tanh(x) \n",
        "        # layer 4\n",
        "        x = nn.functional.avg_pool2d(input=x, kernel_size=2, stride=2)\n",
        "        x = torch.tanh(x) \n",
        "        # layer 5\n",
        "        x = self.conv3(x)\n",
        "        x = torch.tanh(x) \n",
        "        # layer 6\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.tanh(x) \n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "        # x = nn.functional.softmax(x, dim=1)  # remove softmax if using crossEntropy since it applies the softmax function too\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_batch_by_idx(train_loader, batch_idx):\n",
        "    # Calculate start and end indices for the batch\n",
        "    start_idx = batch_idx * train_loader.batch_size\n",
        "    end_idx = start_idx + train_loader.batch_size\n",
        "    \n",
        "    if end_idx > len(train_loader.dataset):\n",
        "        end_idx = len(train_loader.dataset)\n",
        "\n",
        "    # Fetch the data and target tensors for that batch\n",
        "    data_list, target_list = [], []\n",
        "    for idx in range(start_idx, end_idx):\n",
        "        data, target = train_loader.dataset[idx]\n",
        "        data_list.append(data)\n",
        "        target_list.append(target)\n",
        "\n",
        "    # Stack the list into a batch\n",
        "    data_batch = torch.stack(data_list)\n",
        "    target_batch = torch.tensor(target_list)\n",
        "\n",
        "    return data_batch, target_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_model(seed=42):\n",
        "    set_seed(seed)\n",
        "    model = LeNet5()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6nD9nuLc4A3",
        "outputId": "39475260-144c-4f3b-d98a-6894043914e0"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # Sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {avg_test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n",
        "\n",
        "    return avg_test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_vector(state_dict):\n",
        "    flat_vector = []\n",
        "    shapes = {}\n",
        "\n",
        "    for name, tensor in state_dict.items():\n",
        "        flattened_tensor = tensor.view(-1)  # Flatten the tensor into a 1D vector\n",
        "        flat_vector.append(flattened_tensor)\n",
        "        shapes[name] = tensor.shape  # Store the original shape\n",
        "\n",
        "    # Concatenate all flattened tensors into a single 1D vector\n",
        "    flat_vector = torch.cat(flat_vector)\n",
        "\n",
        "    return flat_vector, shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_to_state_dict(flat_vector, shapes):\n",
        "    reconstructed_state_dict = {}\n",
        "    current_index = 0\n",
        "\n",
        "    for name, shape in shapes.items():\n",
        "        # Calculate the number of elements in the tensor\n",
        "        num_elements = torch.prod(torch.tensor(shape))\n",
        "        # Extract the corresponding portion from the flat vector\n",
        "        flattened_tensor = flat_vector[current_index:current_index + num_elements]\n",
        "        # Reshape the 1D tensor back to its original shape\n",
        "        tensor = flattened_tensor.view(shape)\n",
        "        # Add the tensor back to the state_dict\n",
        "        reconstructed_state_dict[name] = tensor\n",
        "        # Update the current index\n",
        "        current_index += num_elements\n",
        "\n",
        "    return reconstructed_state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GA:\n",
        "    def __init__(self, \n",
        "                 seed: int, \n",
        "                 d: int, \n",
        "                 q: int, \n",
        "                 device: torch.device = torch.device(\"cpu\")) -> None:\n",
        "        self.seed = seed\n",
        "        self.d = d\n",
        "        self.q = q\n",
        "        self.device = device\n",
        "        torch.manual_seed(self.seed)\n",
        "        \n",
        "        print(f'GA initialized with seed={seed}, d={d}, q={q}, device={device}')\n",
        "        \n",
        "    def G(self) -> torch.Tensor:\n",
        "        return torch.rand(self.d, self.q).to(self.device)\n",
        "    \n",
        "    def w(self, delta: torch.Tensor) -> torch.Tensor:\n",
        "        GT = self.G().t()  # Transpose the tensor\n",
        "        return torch.matmul(GT, delta) / self.q\n",
        "    \n",
        "    def delta(self, w: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.matmul(self.G(), w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(tensor: torch.Tensor, min_val: float = 0.0, max_val: float = 1.0) -> torch.Tensor:\n",
        "    tensor_min = tensor.min()\n",
        "    tensor_max = tensor.max()\n",
        "    \n",
        "    # Scale tensor to range [0, 1]\n",
        "    normalized_tensor = (tensor - tensor_min) / (tensor_max - tensor_min)\n",
        "    \n",
        "    # Scale to desired range [min_val, max_val]\n",
        "    normalized_tensor = normalized_tensor * (max_val - min_val) + min_val\n",
        "    \n",
        "    return normalized_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, batch_idx, track_weights=False):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    # current weights\n",
        "    w_t = {name: weights.clone().detach().cpu() for name, weights in model.state_dict().items()}\n",
        "    \n",
        "    data, target = get_batch_by_idx(train_loader, batch_idx)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    \n",
        "    # new weights\n",
        "    w_t_plus_1 = {name: weights.clone().detach().cpu() for name, weights in model.state_dict().items()}\n",
        "    updates = {\n",
        "        name: (w_t[name] - w_t_plus_1[name])\n",
        "        for name in w_t_plus_1}\n",
        "    \n",
        "    return updates, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rounds: 235, Batch Size: 256\n",
            "Running round 1/235\n",
            "GA initialized with seed=45, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 99/10000 (1%)\n",
            "\n",
            "Running round 2/235\n",
            "GA initialized with seed=90, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0025, Accuracy: 976/10000 (10%)\n",
            "\n",
            "Running round 3/235\n",
            "GA initialized with seed=20, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 4/235\n",
            "GA initialized with seed=22, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1912/10000 (19%)\n",
            "\n",
            "Running round 5/235\n",
            "GA initialized with seed=32, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1986/10000 (20%)\n",
            "\n",
            "Running round 6/235\n",
            "GA initialized with seed=44, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 7/235\n",
            "GA initialized with seed=20, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 8/235\n",
            "GA initialized with seed=77, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 9/235\n",
            "GA initialized with seed=41, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 10/235\n",
            "GA initialized with seed=14, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2052/10000 (21%)\n",
            "\n",
            "Running round 11/235\n",
            "GA initialized with seed=55, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 12/235\n",
            "GA initialized with seed=61, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1985/10000 (20%)\n",
            "\n",
            "Running round 13/235\n",
            "GA initialized with seed=69, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 14/235\n",
            "GA initialized with seed=68, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1985/10000 (20%)\n",
            "\n",
            "Running round 15/235\n",
            "GA initialized with seed=54, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2055/10000 (21%)\n",
            "\n",
            "Running round 16/235\n",
            "GA initialized with seed=59, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 17/235\n",
            "GA initialized with seed=23, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 18/235\n",
            "GA initialized with seed=62, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 19/235\n",
            "GA initialized with seed=96, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 20/235\n",
            "GA initialized with seed=66, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 21/235\n",
            "GA initialized with seed=15, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 22/235\n",
            "GA initialized with seed=81, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1709/10000 (17%)\n",
            "\n",
            "Running round 23/235\n",
            "GA initialized with seed=96, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 24/235\n",
            "GA initialized with seed=51, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 25/235\n",
            "GA initialized with seed=86, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 26/235\n",
            "GA initialized with seed=99, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 27/235\n",
            "GA initialized with seed=66, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 28/235\n",
            "GA initialized with seed=64, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 29/235\n",
            "GA initialized with seed=50, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 30/235\n",
            "GA initialized with seed=40, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 31/235\n",
            "GA initialized with seed=96, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 32/235\n",
            "GA initialized with seed=66, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 33/235\n",
            "GA initialized with seed=38, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 34/235\n",
            "GA initialized with seed=95, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 35/235\n",
            "GA initialized with seed=20, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1985/10000 (20%)\n",
            "\n",
            "Running round 36/235\n",
            "GA initialized with seed=96, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 37/235\n",
            "GA initialized with seed=9, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1985/10000 (20%)\n",
            "\n",
            "Running round 38/235\n",
            "GA initialized with seed=34, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 39/235\n",
            "GA initialized with seed=16, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 40/235\n",
            "GA initialized with seed=72, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 41/235\n",
            "GA initialized with seed=67, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 42/235\n",
            "GA initialized with seed=55, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 43/235\n",
            "GA initialized with seed=5, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 44/235\n",
            "GA initialized with seed=45, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 45/235\n",
            "GA initialized with seed=0, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1954/10000 (20%)\n",
            "\n",
            "Running round 46/235\n",
            "GA initialized with seed=100, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 47/235\n",
            "GA initialized with seed=55, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 48/235\n",
            "GA initialized with seed=37, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 49/235\n",
            "GA initialized with seed=60, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 50/235\n",
            "GA initialized with seed=54, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 51/235\n",
            "GA initialized with seed=1, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1273/10000 (13%)\n",
            "\n",
            "Running round 52/235\n",
            "GA initialized with seed=84, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1911/10000 (19%)\n",
            "\n",
            "Running round 53/235\n",
            "GA initialized with seed=93, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 54/235\n",
            "GA initialized with seed=47, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1911/10000 (19%)\n",
            "\n",
            "Running round 55/235\n",
            "GA initialized with seed=27, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 56/235\n",
            "GA initialized with seed=10, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 57/235\n",
            "GA initialized with seed=81, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 58/235\n",
            "GA initialized with seed=82, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1310/10000 (13%)\n",
            "\n",
            "Running round 59/235\n",
            "GA initialized with seed=29, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1986/10000 (20%)\n",
            "\n",
            "Running round 60/235\n",
            "GA initialized with seed=62, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1369/10000 (14%)\n",
            "\n",
            "Running round 61/235\n",
            "GA initialized with seed=8, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 62/235\n",
            "GA initialized with seed=62, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 63/235\n",
            "GA initialized with seed=72, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1986/10000 (20%)\n",
            "\n",
            "Running round 64/235\n",
            "GA initialized with seed=19, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 65/235\n",
            "GA initialized with seed=6, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 66/235\n",
            "GA initialized with seed=13, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 67/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0024, Accuracy: 1374/10000 (14%)\n",
            "\n",
            "Running round 68/235\n",
            "GA initialized with seed=57, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 69/235\n",
            "GA initialized with seed=98, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 70/235\n",
            "GA initialized with seed=35, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1986/10000 (20%)\n",
            "\n",
            "Running round 71/235\n",
            "GA initialized with seed=94, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 72/235\n",
            "GA initialized with seed=79, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 73/235\n",
            "GA initialized with seed=18, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 74/235\n",
            "GA initialized with seed=98, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 75/235\n",
            "GA initialized with seed=48, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 76/235\n",
            "GA initialized with seed=79, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 77/235\n",
            "GA initialized with seed=34, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 78/235\n",
            "GA initialized with seed=44, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 79/235\n",
            "GA initialized with seed=99, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 80/235\n",
            "GA initialized with seed=5, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 81/235\n",
            "GA initialized with seed=17, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 82/235\n",
            "GA initialized with seed=27, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 83/235\n",
            "GA initialized with seed=33, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 84/235\n",
            "GA initialized with seed=32, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 85/235\n",
            "GA initialized with seed=27, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1401/10000 (14%)\n",
            "\n",
            "Running round 86/235\n",
            "GA initialized with seed=15, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 87/235\n",
            "GA initialized with seed=9, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 88/235\n",
            "GA initialized with seed=59, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1369/10000 (14%)\n",
            "\n",
            "Running round 89/235\n",
            "GA initialized with seed=48, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 90/235\n",
            "GA initialized with seed=36, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 91/235\n",
            "GA initialized with seed=99, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 92/235\n",
            "GA initialized with seed=24, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 93/235\n",
            "GA initialized with seed=51, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 94/235\n",
            "GA initialized with seed=64, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 95/235\n",
            "GA initialized with seed=70, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 96/235\n",
            "GA initialized with seed=65, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 97/235\n",
            "GA initialized with seed=45, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 98/235\n",
            "GA initialized with seed=72, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 99/235\n",
            "GA initialized with seed=43, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 100/235\n",
            "GA initialized with seed=50, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 101/235\n",
            "GA initialized with seed=0, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 102/235\n",
            "GA initialized with seed=10, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1401/10000 (14%)\n",
            "\n",
            "Running round 103/235\n",
            "GA initialized with seed=62, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 104/235\n",
            "GA initialized with seed=20, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1310/10000 (13%)\n",
            "\n",
            "Running round 105/235\n",
            "GA initialized with seed=61, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 106/235\n",
            "GA initialized with seed=95, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 107/235\n",
            "GA initialized with seed=21, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 108/235\n",
            "GA initialized with seed=8, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 109/235\n",
            "GA initialized with seed=26, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 110/235\n",
            "GA initialized with seed=72, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1954/10000 (20%)\n",
            "\n",
            "Running round 111/235\n",
            "GA initialized with seed=76, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 112/235\n",
            "GA initialized with seed=15, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 113/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 114/235\n",
            "GA initialized with seed=48, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1953/10000 (20%)\n",
            "\n",
            "Running round 115/235\n",
            "GA initialized with seed=1, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 116/235\n",
            "GA initialized with seed=15, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 117/235\n",
            "GA initialized with seed=31, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 118/235\n",
            "GA initialized with seed=71, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 119/235\n",
            "GA initialized with seed=4, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 120/235\n",
            "GA initialized with seed=18, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 121/235\n",
            "GA initialized with seed=34, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 122/235\n",
            "GA initialized with seed=47, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 123/235\n",
            "GA initialized with seed=97, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 124/235\n",
            "GA initialized with seed=7, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 125/235\n",
            "GA initialized with seed=8, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 126/235\n",
            "GA initialized with seed=99, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 127/235\n",
            "GA initialized with seed=54, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 128/235\n",
            "GA initialized with seed=49, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 129/235\n",
            "GA initialized with seed=82, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 130/235\n",
            "GA initialized with seed=23, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 131/235\n",
            "GA initialized with seed=52, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 132/235\n",
            "GA initialized with seed=88, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1227/10000 (12%)\n",
            "\n",
            "Running round 133/235\n",
            "GA initialized with seed=87, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 134/235\n",
            "GA initialized with seed=71, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 135/235\n",
            "GA initialized with seed=16, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1373/10000 (14%)\n",
            "\n",
            "Running round 136/235\n",
            "GA initialized with seed=53, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1910/10000 (19%)\n",
            "\n",
            "Running round 137/235\n",
            "GA initialized with seed=53, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1373/10000 (14%)\n",
            "\n",
            "Running round 138/235\n",
            "GA initialized with seed=70, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 139/235\n",
            "GA initialized with seed=40, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1373/10000 (14%)\n",
            "\n",
            "Running round 140/235\n",
            "GA initialized with seed=7, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 141/235\n",
            "GA initialized with seed=44, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1368/10000 (14%)\n",
            "\n",
            "Running round 142/235\n",
            "GA initialized with seed=17, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 143/235\n",
            "GA initialized with seed=84, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1368/10000 (14%)\n",
            "\n",
            "Running round 144/235\n",
            "GA initialized with seed=11, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 145/235\n",
            "GA initialized with seed=1, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1226/10000 (12%)\n",
            "\n",
            "Running round 146/235\n",
            "GA initialized with seed=23, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 147/235\n",
            "GA initialized with seed=83, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1269/10000 (13%)\n",
            "\n",
            "Running round 148/235\n",
            "GA initialized with seed=5, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 149/235\n",
            "GA initialized with seed=52, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 150/235\n",
            "GA initialized with seed=91, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1400/10000 (14%)\n",
            "\n",
            "Running round 151/235\n",
            "GA initialized with seed=66, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 152/235\n",
            "GA initialized with seed=100, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 153/235\n",
            "GA initialized with seed=57, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 154/235\n",
            "GA initialized with seed=42, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 155/235\n",
            "GA initialized with seed=25, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 156/235\n",
            "GA initialized with seed=29, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 157/235\n",
            "GA initialized with seed=68, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 158/235\n",
            "GA initialized with seed=84, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 159/235\n",
            "GA initialized with seed=83, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 160/235\n",
            "GA initialized with seed=92, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 161/235\n",
            "GA initialized with seed=35, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 162/235\n",
            "GA initialized with seed=91, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 163/235\n",
            "GA initialized with seed=23, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1227/10000 (12%)\n",
            "\n",
            "Running round 164/235\n",
            "GA initialized with seed=32, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1870/10000 (19%)\n",
            "\n",
            "Running round 165/235\n",
            "GA initialized with seed=35, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1049/10000 (10%)\n",
            "\n",
            "Running round 166/235\n",
            "GA initialized with seed=54, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 167/235\n",
            "GA initialized with seed=0, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 168/235\n",
            "GA initialized with seed=75, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 169/235\n",
            "GA initialized with seed=1, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1401/10000 (14%)\n",
            "\n",
            "Running round 170/235\n",
            "GA initialized with seed=89, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1871/10000 (19%)\n",
            "\n",
            "Running round 171/235\n",
            "GA initialized with seed=72, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 172/235\n",
            "GA initialized with seed=86, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 173/235\n",
            "GA initialized with seed=91, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1992/10000 (20%)\n",
            "\n",
            "Running round 174/235\n",
            "GA initialized with seed=61, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 175/235\n",
            "GA initialized with seed=69, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1870/10000 (19%)\n",
            "\n",
            "Running round 176/235\n",
            "GA initialized with seed=44, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1709/10000 (17%)\n",
            "\n",
            "Running round 177/235\n",
            "GA initialized with seed=78, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 178/235\n",
            "GA initialized with seed=2, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1402/10000 (14%)\n",
            "\n",
            "Running round 179/235\n",
            "GA initialized with seed=38, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 180/235\n",
            "GA initialized with seed=39, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1375/10000 (14%)\n",
            "\n",
            "Running round 181/235\n",
            "GA initialized with seed=91, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 182/235\n",
            "GA initialized with seed=14, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 183/235\n",
            "GA initialized with seed=21, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 184/235\n",
            "GA initialized with seed=52, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1375/10000 (14%)\n",
            "\n",
            "Running round 185/235\n",
            "GA initialized with seed=12, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 186/235\n",
            "GA initialized with seed=71, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 187/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 188/235\n",
            "GA initialized with seed=32, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 189/235\n",
            "GA initialized with seed=8, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 190/235\n",
            "GA initialized with seed=13, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 191/235\n",
            "GA initialized with seed=48, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1870/10000 (19%)\n",
            "\n",
            "Running round 192/235\n",
            "GA initialized with seed=29, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1306/10000 (13%)\n",
            "\n",
            "Running round 193/235\n",
            "GA initialized with seed=97, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 194/235\n",
            "GA initialized with seed=76, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1375/10000 (14%)\n",
            "\n",
            "Running round 195/235\n",
            "GA initialized with seed=78, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 196/235\n",
            "GA initialized with seed=94, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 197/235\n",
            "GA initialized with seed=59, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 198/235\n",
            "GA initialized with seed=19, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1228/10000 (12%)\n",
            "\n",
            "Running round 199/235\n",
            "GA initialized with seed=81, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 200/235\n",
            "GA initialized with seed=74, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 201/235\n",
            "GA initialized with seed=70, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 202/235\n",
            "GA initialized with seed=24, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1870/10000 (19%)\n",
            "\n",
            "Running round 203/235\n",
            "GA initialized with seed=52, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 204/235\n",
            "GA initialized with seed=57, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 205/235\n",
            "GA initialized with seed=39, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 206/235\n",
            "GA initialized with seed=39, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 207/235\n",
            "GA initialized with seed=16, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 208/235\n",
            "GA initialized with seed=59, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 209/235\n",
            "GA initialized with seed=57, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 210/235\n",
            "GA initialized with seed=20, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 211/235\n",
            "GA initialized with seed=5, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 212/235\n",
            "GA initialized with seed=63, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 213/235\n",
            "GA initialized with seed=83, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 214/235\n",
            "GA initialized with seed=60, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 215/235\n",
            "GA initialized with seed=34, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 216/235\n",
            "GA initialized with seed=68, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 217/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 218/235\n",
            "GA initialized with seed=56, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Running round 219/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 220/235\n",
            "GA initialized with seed=4, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1189/10000 (12%)\n",
            "\n",
            "Running round 221/235\n",
            "GA initialized with seed=22, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 222/235\n",
            "GA initialized with seed=58, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2051/10000 (21%)\n",
            "\n",
            "Running round 223/235\n",
            "GA initialized with seed=66, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 224/235\n",
            "GA initialized with seed=100, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 225/235\n",
            "GA initialized with seed=40, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 226/235\n",
            "GA initialized with seed=24, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 227/235\n",
            "GA initialized with seed=0, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1375/10000 (14%)\n",
            "\n",
            "Running round 228/235\n",
            "GA initialized with seed=25, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 229/235\n",
            "GA initialized with seed=24, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 1987/10000 (20%)\n",
            "\n",
            "Running round 230/235\n",
            "GA initialized with seed=47, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 2083/10000 (21%)\n",
            "\n",
            "Running round 231/235\n",
            "GA initialized with seed=10, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 232/235\n",
            "GA initialized with seed=48, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1909/10000 (19%)\n",
            "\n",
            "Running round 233/235\n",
            "GA initialized with seed=10, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 2056/10000 (21%)\n",
            "\n",
            "Running round 234/235\n",
            "GA initialized with seed=27, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 1952/10000 (20%)\n",
            "\n",
            "Running round 235/235\n",
            "GA initialized with seed=3, d=61706, q=1000, device=cpu\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 1987/10000 (20%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "accuracies = []\n",
        "deltas = []\n",
        "gws = []\n",
        "approximation_errors = []\n",
        "\n",
        "rounds = len(train_loader)\n",
        "print(f\"Rounds: {rounds}, Batch Size: {train_loader.batch_size}\")\n",
        "\n",
        "model = initialize_model(seed=1829).to(device)\n",
        "lr = 0.01\n",
        "\n",
        "for round in range(1, 1 + rounds):\n",
        "    print(f\"Running round {round}/{rounds}\")\n",
        "\n",
        "    updates, loss = train(\n",
        "        model=model,\n",
        "        device=device,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optim.Adam(model.parameters(), lr=lr),\n",
        "        criterion=nn.CrossEntropyLoss(),\n",
        "        batch_idx=round - 1)\n",
        "    \n",
        "    # apply GA\n",
        "    updates_flattened, shapes = flatten_vector(updates)\n",
        "    \n",
        "    seed = random.randint(0, 100)\n",
        "    ga = GA(seed=seed, \n",
        "        d=len(updates_flattened), \n",
        "        q=int(1e3),\n",
        "        device=device)\n",
        "    w = ga.w(delta=updates_flattened)\n",
        "    gw = ga.delta(w=w)\n",
        "    \n",
        "    # calculate error\n",
        "    error = updates_flattened - gw\n",
        "    l2_norm_error = torch.norm(error, p=2)\n",
        "    approximation_errors.append(l2_norm_error)\n",
        "    \n",
        "    # apply approximated updates\n",
        "    curr_weights_dict = {name: weights.clone().detach().cpu() for name, weights in model.state_dict().items()}\n",
        "    curr_weights, _ = flatten_vector(curr_weights_dict)\n",
        "    new_weights = curr_weights + gw\n",
        "    \n",
        "    new_weights_dict = vector_to_state_dict(flat_vector=new_weights,\n",
        "                                            shapes=shapes)\n",
        "    \n",
        "    model.load_state_dict(state_dict=new_weights_dict)\n",
        "\n",
        "    avg_test_loss, accuracy = test(model, device, test_loader, criterion=nn.CrossEntropyLoss())\n",
        "\n",
        "    # for plotting\n",
        "    train_losses.append(float(loss))\n",
        "    test_losses.append(avg_test_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    deltas.append(updates_flattened)\n",
        "    gws.append(gw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>delta_1</th>\n",
              "      <th>delta_2</th>\n",
              "      <th>delta_3</th>\n",
              "      <th>Gw_1</th>\n",
              "      <th>Gw_2</th>\n",
              "      <th>Gw_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.440190</td>\n",
              "      <td>-2.712518</td>\n",
              "      <td>-0.820730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.451413</td>\n",
              "      <td>-2.706788</td>\n",
              "      <td>-0.883582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.454962</td>\n",
              "      <td>-2.752032</td>\n",
              "      <td>-0.855184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.452019</td>\n",
              "      <td>-2.669443</td>\n",
              "      <td>-0.860320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.460303</td>\n",
              "      <td>-2.696427</td>\n",
              "      <td>-0.873780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61701</th>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.458207</td>\n",
              "      <td>-2.611437</td>\n",
              "      <td>-0.847382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61702</th>\n",
              "      <td>0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.445088</td>\n",
              "      <td>-2.653844</td>\n",
              "      <td>-0.840851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61703</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.444780</td>\n",
              "      <td>-2.609738</td>\n",
              "      <td>-0.887027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61704</th>\n",
              "      <td>0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.431849</td>\n",
              "      <td>-2.578373</td>\n",
              "      <td>-0.862163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61705</th>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.435804</td>\n",
              "      <td>-2.673199</td>\n",
              "      <td>-0.873659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61706 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        delta_1  delta_2  delta_3      Gw_1      Gw_2      Gw_3\n",
              "0      0.009996     0.01     0.00  0.440190 -2.712518 -0.820730\n",
              "1     -0.010000    -0.01     0.00  0.451413 -2.706788 -0.883582\n",
              "2     -0.010000    -0.01     0.00  0.454962 -2.752032 -0.855184\n",
              "3     -0.010000    -0.01     0.00  0.452019 -2.669443 -0.860320\n",
              "4     -0.010000    -0.01     0.00  0.460303 -2.696427 -0.873780\n",
              "...         ...      ...      ...       ...       ...       ...\n",
              "61701  0.010000     0.01    -0.01  0.458207 -2.611437 -0.847382\n",
              "61702  0.010000    -0.01    -0.01  0.445088 -2.653844 -0.840851\n",
              "61703 -0.010000     0.01    -0.01  0.444780 -2.609738 -0.887027\n",
              "61704  0.010000    -0.01    -0.01  0.431849 -2.578373 -0.862163\n",
              "61705 -0.010000    -0.01     0.01  0.435804 -2.673199 -0.873659\n",
              "\n",
              "[61706 rows x 6 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data = {\n",
        "    'delta_1' : [float(x) for x in deltas[0]],\n",
        "    'delta_2' : [float(x) for x in deltas[1]],\n",
        "    'delta_3' : [float(x) for x in deltas[2]],\n",
        "    'Gw_1' : [float(x) for x in gws[0]],\n",
        "    'Gw_2' : [float(x) for x in gws[1]],\n",
        "    'Gw_3' : [float(x) for x in gws[2]]\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/66/p1j5g0w12bx003hgq7kkdg5w0000gn/T/ipykernel_18009/3466956203.py:14: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x='variable', y='value', data=df_melted, palette=palette)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Melt the DataFrame for easier plotting\n",
        "df_melted = df.melt(var_name='variable', value_name='value')\n",
        "\n",
        "# Set the color palette\n",
        "palette = {\n",
        "    'delta_1': 'blue', 'delta_2': 'blue', 'delta_3': 'blue',\n",
        "    'Gw_1': 'orange', 'Gw_2': 'orange', 'Gw_3': 'orange'\n",
        "}\n",
        "\n",
        "# Create the box plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(x='variable', y='value', data=df_melted, palette=palette)\n",
        "\n",
        "# Customize plot\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Box Plots of Data')\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Values')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python poetry_kernel",
      "language": "python",
      "name": "poetry_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
