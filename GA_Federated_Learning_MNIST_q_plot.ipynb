{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KRVG5spLX-G6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [5, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qQWXppI8c3vL"
      },
      "outputs": [],
      "source": [
        "train_dataset = MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_dataset, dev_dataset = random_split(train_dataset, [int(len(train_dataset) * 0.83), int(len(train_dataset) * 0.17)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6nD9nuLc4A3",
        "outputId": "52b968de-bd84-45ec-e63a-e3f9896e4721"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(49800, 10200, 10000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_train_size = len(train_dataset)\n",
        "total_test_size = len(test_dataset)\n",
        "total_dev_size = len(dev_dataset)\n",
        "\n",
        "classes = 10\n",
        "input_dim = 784\n",
        "\n",
        "num_clients = 8\n",
        "rounds = 1\n",
        "batch_size = 128\n",
        "epochs_per_client = 3\n",
        "learning_rate = 0.1\n",
        "\n",
        "total_train_size, total_dev_size, total_test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JbqTUDwzc8AD"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader(DataLoader):\n",
        "        def __init__(self, dl, device):\n",
        "            self.dl = dl\n",
        "            self.device = device\n",
        "\n",
        "        def __iter__(self):\n",
        "            for batch in self.dl:\n",
        "                yield to_device(batch, self.device)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dl)\n",
        "\n",
        "device = get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4o5IBObdBcP"
      },
      "source": [
        "Define Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8c6p9cH1dB_g"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "class FederatedNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 20, 7)\n",
        "        self.conv2 = torch.nn.Conv2d(20, 40, 7)\n",
        "        self.maxpool = torch.nn.MaxPool2d(2, 2)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.linear = torch.nn.Linear(2560, 10)\n",
        "        self.non_linearity = torch.nn.functional.relu\n",
        "        self.track_layers = {'conv1': self.conv1, 'conv2': self.conv2, 'linear': self.linear}\n",
        "\n",
        "    def forward(self, x_batch):\n",
        "        out = self.conv1(x_batch)\n",
        "        out = self.non_linearity(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.non_linearity(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def get_track_layers(self):\n",
        "        return self.track_layers\n",
        "\n",
        "    def apply_parameters(self, parameters_dict):\n",
        "        with torch.no_grad():\n",
        "            for layer_name in parameters_dict:\n",
        "                self.track_layers[layer_name].weight.data *= 0\n",
        "                self.track_layers[layer_name].bias.data *= 0\n",
        "                self.track_layers[layer_name].weight.data += parameters_dict[layer_name]['weight']\n",
        "                self.track_layers[layer_name].bias.data += parameters_dict[layer_name]['bias']\n",
        "\n",
        "    def get_parameters(self, deep_copy = True):\n",
        "        parameters_dict = dict()\n",
        "        for layer_name in self.track_layers:\n",
        "            parameters_dict[layer_name] = {\n",
        "                'weight': self.track_layers[layer_name].weight.data,\n",
        "                'bias': self.track_layers[layer_name].bias.data\n",
        "            }\n",
        "        if deep_copy:\n",
        "            params_clone = copy.deepcopy(parameters_dict)\n",
        "            return params_clone\n",
        "        else:\n",
        "            return parameters_dict\n",
        "\n",
        "    def batch_accuracy(self, outputs, labels):\n",
        "        with torch.no_grad():\n",
        "            _, predictions = torch.max(outputs, dim=1)\n",
        "            return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
        "\n",
        "    def _process_batch(self, batch):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
        "        accuracy = self.batch_accuracy(outputs, labels)\n",
        "        return (loss, accuracy)\n",
        "\n",
        "    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n",
        "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n",
        "        optimizer = opt(self.parameters(), lr)\n",
        "        history = []\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "            accs = []\n",
        "            for batch in dataloader:\n",
        "                loss, acc = self._process_batch(batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                loss.detach()\n",
        "                losses.append(loss)\n",
        "                accs.append(acc)\n",
        "            avg_loss = torch.stack(losses).mean().item()\n",
        "            avg_acc = torch.stack(accs).mean().item()\n",
        "            history.append((avg_loss, avg_acc))\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, dataset, batch_size=128):\n",
        "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n",
        "        losses = []\n",
        "        accs = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                loss, acc = self._process_batch(batch)\n",
        "                losses.append(loss)\n",
        "                accs.append(acc)\n",
        "        avg_loss = torch.stack(losses).mean().item()\n",
        "        avg_acc = torch.stack(accs).mean().item()\n",
        "        return (avg_loss, avg_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j7tag7MdKL3"
      },
      "source": [
        "Define Client class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IhjbDhQEdJiw"
      },
      "outputs": [],
      "source": [
        "class Client:\n",
        "    def __init__(self, client_id, dataset):\n",
        "        self.client_id = client_id\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def get_dataset_size(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_client_id(self):\n",
        "        return self.client_id\n",
        "\n",
        "    def __difference(self, params1 : dict, params2 : dict):\n",
        "        diff = {}\n",
        "        for layer in params1.keys():\n",
        "            diff[layer] = {}\n",
        "            for key in params1[layer].keys():\n",
        "                diff[layer][key] = params1[layer][key] - params2[layer][key]\n",
        "        return diff\n",
        "\n",
        "    def train(self, parameters_dict):\n",
        "        net = to_device(FederatedNet(), device)\n",
        "        net.apply_parameters(parameters_dict)\n",
        "        wt = net.get_parameters(deep_copy=True)\n",
        "        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n",
        "        print('{}: Loss = {}, Accuracy = {}'.format(self.client_id, round(train_history[-1][0], 4), round(train_history[-1][1], 4)))\n",
        "        wt_plus_1 = net.get_parameters(deep_copy=True)\n",
        "        update = self.__difference(wt, wt_plus_1)\n",
        "        return update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU2hdlwgdNWe"
      },
      "source": [
        "Setup clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dQRK-5VRFvlk"
      },
      "outputs": [],
      "source": [
        "def diff_l2_norm(wt, wt_plus_1):\n",
        "    total_diff = 0\n",
        "    for layer in wt.keys():\n",
        "        for key in wt[layer].keys():\n",
        "            diff = wt[layer][key] - wt_plus_1[layer][key]\n",
        "            total_diff += torch.sum(diff ** 2)\n",
        "    l2_norm = torch.sqrt(total_diff)\n",
        "    return l2_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DNnMZxdWFvll"
      },
      "outputs": [],
      "source": [
        "def reconstruct_wt_plus_1(global_params, client_updates):\n",
        "    wt_plus_1 = {}\n",
        "    for layer in global_params.keys():\n",
        "        wt_plus_1[layer] = {}\n",
        "        for key in global_params[layer].keys():\n",
        "            wt_plus_1[layer][key] = global_params[layer][key] - client_updates[layer][key]\n",
        "    return wt_plus_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TFO4EyR6Fvll"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def flatten_dict_to_vector(d):\n",
        "    flat_list = []\n",
        "    shapes = {}\n",
        "\n",
        "    for k1, v1 in d.items():\n",
        "        for k2, tensor in v1.items():\n",
        "            shapes[f'{k1}_{k2}'] = tensor.shape\n",
        "            # Check if tensor is on GPU and move to CPU if necessary\n",
        "            if tensor.is_cuda:\n",
        "                tensor = tensor.cpu()\n",
        "            flat_list.extend(tensor.flatten().numpy())\n",
        "\n",
        "    flat_vector = np.array(flat_list)\n",
        "    return flat_vector, shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F6wSAtnfFvll"
      },
      "outputs": [],
      "source": [
        "def restore_vector_to_dict(flat_vector, shapes):\n",
        "    restored_dict = {}\n",
        "    offset = 0\n",
        "\n",
        "    # Check if CUDA is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for k, shape in shapes.items():\n",
        "        size = np.prod(shape)\n",
        "        tensor_flat = flat_vector[offset:offset + size]\n",
        "        tensor = tensor_flat.clone().detach().reshape(shape).to(device)\n",
        "        # tensor = torch.tensor(tensor_flat).reshape(shape).to(device)  # Send tensor to the appropriate device\n",
        "\n",
        "        k1, k2 = k.split('_')\n",
        "        if k1 not in restored_dict:\n",
        "            restored_dict[k1] = {}\n",
        "        restored_dict[k1][k2] = tensor\n",
        "\n",
        "        offset += size\n",
        "\n",
        "    return restored_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agdNBK3tdQZ1"
      },
      "source": [
        "Start server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YiLTZE10Fvll"
      },
      "outputs": [],
      "source": [
        "examples_per_client = total_train_size // num_clients\n",
        "client_datasets = random_split(train_dataset, [min(i + examples_per_client,\n",
        "           total_train_size) - i for i in range(0, total_train_size, examples_per_client)])\n",
        "clients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAbpZWdgdPMx",
        "outputId": "ab495033-9bd3-4c08-875a-834d9fc4f629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Round 1 ...\n",
            "client_0: Loss = 0.1963, Accuracy = 0.9429\n",
            "client_1: Loss = 0.1852, Accuracy = 0.9453\n",
            "client_2: Loss = 0.1798, Accuracy = 0.9438\n",
            "client_3: Loss = 0.1794, Accuracy = 0.9442\n",
            "client_4: Loss = 0.1741, Accuracy = 0.9476\n",
            "client_5: Loss = 0.1719, Accuracy = 0.9476\n",
            "client_6: Loss = 0.1816, Accuracy = 0.9448\n",
            "client_7: Loss = 0.2027, Accuracy = 0.9363\n",
            "L2 Norm Error between actual vector and decoded vector: tensor(251.2254)\n",
            "After round 1, train_loss = 4804.8535, dev_loss = 4839.2583, dev_acc = 0.0586\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "errors = []\n",
        "start = time()\n",
        "global_net = to_device(FederatedNet(), device)\n",
        "history = []\n",
        "for i in range(rounds):\n",
        "    print('Start Round {} ...'.format(i + 1))\n",
        "    curr_parameters = global_net.get_parameters()\n",
        "    new_parameters = copy.deepcopy(curr_parameters) #dict([(layer_name, {'weight': 0, 'bias': 0}) for layer_name in curr_parameters])\n",
        "    updates = []\n",
        "\n",
        "    # get client updates\n",
        "    for client in clients:\n",
        "        update = client.train(curr_parameters)\n",
        "        updates.append(update)\n",
        "    processed_updates = []\n",
        "\n",
        "    # apply ga to updates\n",
        "    for update in updates:\n",
        "        flat_vector, shapes = flatten_dict_to_vector(update)\n",
        "        d = flat_vector.size\n",
        "        q = 10\n",
        "        random_seed = 42\n",
        "\n",
        "        np.random.seed(random_seed)\n",
        "        G_np = np.random.normal(0, 1, size=(d, int(q)))\n",
        "        G = torch.tensor(G_np, dtype=torch.float32)\n",
        "        w = torch.matmul(G.T, torch.tensor(flat_vector)) / q\n",
        "        delta = torch.matmul(G, w)\n",
        "        restored_wt = restore_vector_to_dict(delta, shapes)\n",
        "        processed_updates.append(restored_wt)\n",
        "\n",
        "    # send updates to the server\n",
        "    for update in processed_updates:\n",
        "        # errors.append(diff_l2_norm(updates[i], update))\n",
        "        client_parameters = reconstruct_wt_plus_1(curr_parameters, update)\n",
        "        fraction = client.get_dataset_size() / total_train_size\n",
        "        for layer_name in client_parameters:\n",
        "            new_parameters[layer_name]['weight'] += fraction * (client_parameters[layer_name]['weight'])\n",
        "            new_parameters[layer_name]['bias'] += fraction * (client_parameters[layer_name]['bias'])\n",
        "    print(f'L2 Norm Error between actual vector and decoded vector:', diff_l2_norm(wt=updates[-1], wt_plus_1=processed_updates[-1]).sum())\n",
        "    global_net.apply_parameters(new_parameters)\n",
        "\n",
        "    train_loss, train_acc = global_net.evaluate(train_dataset)\n",
        "    dev_loss, dev_acc = global_net.evaluate(dev_dataset)\n",
        "    print('After round {}, train_loss = {}, dev_loss = {}, dev_acc = {}\\n'.format(i + 1, round(train_loss, 4),\n",
        "            round(dev_loss, 4), round(dev_acc, 4)))\n",
        "    history.append((train_loss, dev_loss, dev_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4_hgPRjFvlm"
      },
      "outputs": [],
      "source": [
        "print('time took:', time() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW7KF_WXdR5X"
      },
      "outputs": [],
      "source": [
        "plt.plot([i + 1 for i in range(len(history))], [history[i][0] for i in range(len(history))], color='r', label='train loss')\n",
        "plt.plot([i + 1 for i in range(len(history))], [history[i][1] for i in range(len(history))], color='b', label='dev loss')\n",
        "plt.legend()\n",
        "plt.title('Training history')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5EykjcoFvlm"
      },
      "outputs": [],
      "source": [
        "dev_accs = [history[i][2] for i in range(len(history))]\n",
        "# Plot accuracies\n",
        "plt.plot([i + 1 for i in range(len(history))], dev_accs, color='m', label='dev accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy history')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA6Nog0ZFvlm"
      },
      "outputs": [],
      "source": [
        "dev_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywAb19_5Qf1J"
      },
      "outputs": [],
      "source": [
        "updates[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIhE9sCvQUIs"
      },
      "outputs": [],
      "source": [
        "processed_updates[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpdzBH3OQUsx"
      },
      "outputs": [],
      "source": [
        "diff_l2_norm(updates[0], processed_updates[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python poetry_kernel",
      "language": "python",
      "name": "poetry_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
